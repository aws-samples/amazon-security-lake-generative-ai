{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ca60fbc-28c0-4853-bd28-c4570de71bca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Unlock insights for Amazon Security Lake data using Generative AI leveraging Amazon Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8fe2a5-70c7-4700-9929-ac45e0b09d5f",
   "metadata": {},
   "source": [
    "This Jupyter Notebook demonstrates the ability to generate SQL queries with user provided natural language inputs and how that can be accomplished with the assistance of the LangChain framework. It shows how you can utilize Agents, and Tools to work with Amazon Security Lake data.\n",
    "\n",
    "LangChain is a flexible framework that can integrate with a variety of LLMs. This Notebook was written with LangChain version 0.0.345(and langchain_experimental version: 0.0.43) using the \"anthropic.claude-v2\" model from Amazon Bedrock.\n",
    "\n",
    "Also, be sure to install the requirements below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8716deb3-b5d5-4933-8f03-8425c90ac438",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt --quiet\n",
    "\n",
    "#Restart Kernel to use packages\n",
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1ecc8c-60e6-438a-81ea-50c07b9f872f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import langchain_experimental, langchain\n",
    "import matplotlib, pandas\n",
    "\n",
    "print(\"langchain.__version__: \", langchain.__version__)\n",
    "print(\"langchain_experimental.__version__: \", langchain_experimental.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4322a28d-9b65-4a5f-a248-608f8595f58c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Connect to Security Lake database using SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049702d3-019b-471c-8755-63c6db137b28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "ACCOUNT_ID = os.environ[\"AWS_ACCOUNT_ID\"]\n",
    "region_name = os.environ.get('REGION_NAME', 'us-east-1')"
    "region_fmt = region_name.replace("-","_")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baffc725-10ca-4cf7-a062-aeb5d1c34b8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import SQLDatabase\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#Amazon Security Lake Database\n",
    "SCHEMA_NAME = f\"amazon_security_lake_glue_db_{region_fmt}\"\n",
    "\n",
    "#S3 Staging location for Athena query output results and this will be created by deploying the Cloud Formation stack\n",
    "S3_STAGING_DIR = f's3://athena-ml-insights-bucket-results-{ACCOUNT_ID}/output/'\n",
    "\n",
    "#AWS region where the Amazon Security lake database is created\n",
    "AWS_REGION = \"us-east-1\"\n",
    "\n",
    "\n",
    "engine_athena = create_engine(\n",
    "    \"awsathena+rest://@athena.{}.amazonaws.com:443/{}?s3_staging_dir{}&work_group=security_lake_insights\".\n",
    "    format(AWS_REGION, SCHEMA_NAME, S3_STAGING_DIR)\n",
    ")\n",
    "\n",
    "athena_db = SQLDatabase(engine_athena)\n",
    "db = athena_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82166bc8-3788-47a8-8fa4-ad2ac4d4e86b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define LLM and endpoint url to invoke model, we will be using claude-v2 from Anthropic available within Amazon Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898a43eb-bf6a-4930-b503-fc70b10785d8",
   "metadata": {},
   "source": [
    "Claude v2 is Anthropic's most powerful model, which excels at a wide range of tasks from sophisticated dialogue and creative content generation to detailed instruction following.\n",
    "There is also another faster and cheaper model available from Anthropic which is Claude Instant v1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2bed95-6f02-4bfe-909d-75ca2e464b71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "import os\n",
    "\n",
    "model_id= \"anthropic.claude-v2\"\n",
    "\n",
    "llm = Bedrock(\n",
    "    model_id=model_id,\n",
    "    # Do not neet to provide - defaults to this notebook's region -- https://api.python.langchain.com/en/latest/llms/langchain.llms.bedrock.Bedrock.html#langchain.llms.bedrock.Bedrock.region_name\n",
    "    # region_name=region_name,\n",
    "    endpoint_url=f\"https://bedrock-runtime.{region_name}.amazonaws.com\",\n",
    ")\n",
    "\n",
    "llm.model_kwargs = {'temperature':0.0,\n",
    "                    'top_p':0.0,\n",
    "                    'top_k':0,\n",
    "                    'max_tokens_to_sample': 4096}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfd682c-637e-4169-b1a1-f84babe41d02",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd0b94-643a-45d7-81f6-92ec21bd34cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0caf523f-7d72-43a2-b1a1-37503d0b4874",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Provide list of tools for Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f0fd75-4bcb-4a48-9254-07e8700a3984",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Custom tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc434c7-b08b-47a9-91c5-dfc2657cce4c",
   "metadata": {},
   "source": [
    "Tools are interfaces that an agent can use to interact. Here we will be using SQL and Python tools to help agent determine the right action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571b9841-dd17-4d67-9ce6-cbba40c529fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.tools.sql_database.tool import InfoSQLDatabaseTool, QuerySQLDataBaseTool\n",
    "\n",
    "class InfoSQLDatabaseTool_custom(InfoSQLDatabaseTool):\n",
    "    name= \"sql_db_schema_and_sample_rows\"\n",
    "    description= '\\n    Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables.    \\n\\n    Example Input: \"table1, table2, table3\"\\n    '\n",
    "    \n",
    "    def _run(self, tables: list[str]) -> str:\n",
    "        list_tables= tables.replace(' ', '').split(',')\n",
    "        \n",
    "        schema_str= ''\n",
    "        for table in list_tables:\n",
    "            schema_rows_str= super()._run(table)\n",
    "            row_str= schema_rows_str[schema_rows_str.find('/*'):]   \n",
    "            \n",
    "            schema_rows= QuerySQLDataBaseTool(db=db)._run(f\"SHOW CREATE TABLE `{table}`\")[3:-4]\n",
    "            schema_rows_formatted=schema_rows.replace(\"',), ('  \", '\\n').replace(\"',), ('\", '\\n').replace(\"',), (\\\"  \", '\\n').replace(', \",), (\"  ', '\\n')\n",
    "            \n",
    "            schema_str+= row_str + '\\n' + schema_rows_formatted + '\\n\\n'\n",
    "        \n",
    "        return schema_str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcd4bda-138c-4638-9c08-2e7bd02367a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "QuerySQLDataBaseTool_desc= '\\n    Input to this tool is a detailed and correct SQL query, output is a result from the database.\\n    This tool gives access to a real databse.\\n    If the query does not return anything or return blank results, it means the query is correct and returned 0 rows.\\n    If the query is not correct, an error message will be returned.\\n    If an error is returned, re-examine the database using the `sql_db_schema_and_sample_rows` tool, rewrite the query, check the query, and try again.\\n    '\n",
    "import time\n",
    "\n",
    "class QuerySQLDatabaseTool_custom(QuerySQLDataBaseTool):\n",
    "    name= \"sql_db_query\"\n",
    "    description= QuerySQLDataBaseTool_desc\n",
    "        \n",
    "    def _run(self, query: str) -> str:\n",
    "        print()\n",
    "        print('*'*10)            \n",
    "        print(\"Query passed to sql_db_query tool by llm: \\n\", query)\n",
    "        print('*'*10)\n",
    "        print()\n",
    "        \n",
    "        return super()._run(query.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3e2769-4bb9-4848-b901-4e1bb1896d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0d0f303-ef43-4ca1-b1eb-bc71a6a828da",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initialize tools and create a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dfc3a0-49ab-4b3b-a09a-e8309d05c62d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.tools.sql_database.tool import ListSQLDatabaseTool, QuerySQLCheckerTool\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "tools = [\n",
    "QuerySQLDatabaseTool_custom(db=db, description= QuerySQLDataBaseTool_desc),\n",
    "ListSQLDatabaseTool(db=db),\n",
    "PythonREPLTool(),\n",
    "InfoSQLDatabaseTool_custom(db=db),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa97c0eb-757c-417f-83ff-a0c90357255f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18505687-bcfa-4cb3-b99c-b9e9f02483c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Custom output parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2b45d1-4029-4c9c-8254-c4c4db182f58",
   "metadata": {},
   "source": [
    "Use this to ensure Claude via Bedrock replies to be consistent with the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b297f22d-a0e1-409c-87c2-88bd5f9ab609",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "claude_instructions_for_agent = \"\"\"To use a tool, please use the following format:\\n\\nThought: Do I need to use a tool? Yes\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n\\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\\n\\n{ai_prefix}:[your response here]\"\"\"\n",
    "print(claude_instructions_for_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803cfcfc-d157-414d-a85f-98f70f1af0cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import initialize_agent,AgentType,AgentOutputParser\n",
    "from langchain.schema import AgentAction,AgentFinish\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from typing import Union\n",
    "import re\n",
    "\n",
    "class CustomConvoOutputParser(AgentOutputParser):\n",
    "    \"\"\"Output parser for the conversational agent.\"\"\"\n",
    "\n",
    "    ai_prefix: str = \"AI\"\n",
    "    \"\"\"Prefix to use before AI output.\"\"\"\n",
    "\n",
    "    def get_format_instructions(self) -> str:\n",
    "        return claude_instructions_for_agent\n",
    "\n",
    "    def parse(self, text: str) -> Union[AgentAction, AgentFinish]:\n",
    "        regex = r\"Action: (.*?)[\\n]*Action Input:[\\s+]*([\\S\\s]*)\"\n",
    "        match = re.search(regex, text)\n",
    "        if not match:\n",
    "            return AgentFinish(\n",
    "                {\"output\": text.split(f\"{self.ai_prefix}:\")[-1].strip()}, text\n",
    "            )\n",
    "        action = match.group(1)\n",
    "        action_input = match.group(2)\n",
    "        return AgentAction(action.strip().replace('\\n', ' '), action_input.replace('\\n', ' ').strip(\" \").strip('\"'), text)\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"conversational\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b895240b-c81c-4886-bfbb-fb48a5832d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09c9b3b6-ef55-450e-90f1-15728348d7de",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Adding Conversation Buffer Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcb2d09-5dec-4a99-86a0-488dfd5ad374",
   "metadata": {},
   "source": [
    "You can also load messages into a BufferMemory instance by creating and passing in a ChatHistory object. This lets you easily pick up state from past conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d2fa83-1b41-4fde-b1c2-26fe30f4f070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a62b44-1200-4b04-be0f-abc2cda37699",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initialize the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56cfda8-7fd1-49fc-a1c9-8965761cd954",
   "metadata": {},
   "source": [
    "Agents use an LLM to determine which actions to take and in what order. An action can either be using a tool and observing its output, or returning to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb697d-2c45-4670-b146-5565c8954579",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "conversational_agent = initialize_agent(\n",
    "    agent=\"conversational-react-description\",\n",
    "    tools=tools,\n",
    "    llm= llm,\n",
    "    verbose=True,  # Show its work. Set this to False if you're only interested in the final output\n",
    "    # return_direct=True,  # Return the results without sending back to the LLM. False by default\n",
    "    max_iterations=None,\n",
    "    memory=memory,\n",
    "    handle_parsing_errors=False,\n",
    "    agent_kwargs={'format_instructions':claude_instructions_for_agent,'output_parser':CustomConvoOutputParser()}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388e699a-5812-4b83-bdcb-628e547ec6c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Provide instructions to the Agent on how to use Tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93b0e50-76be-4686-a17d-dfa31ecef241",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversational_agent.agent.llm_chain.prompt.template= conversational_agent.agent.llm_chain.prompt.template[conversational_agent.agent.llm_chain.prompt.template.find(\"TOOLS:\\n------\"):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc38ffd-b555-42b5-828b-069eb8987867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phrase= \"To use a tool\"\n",
    "\n",
    "index= conversational_agent.agent.llm_chain.prompt.template.find(phrase)\n",
    "\n",
    "primer= \"\\nINSTRUCTIONS:\\n-------------\\n\\n\"\n",
    "\n",
    "conversational_agent.agent.llm_chain.prompt.template= conversational_agent.agent.llm_chain.prompt.template[:index] + primer + conversational_agent.agent.llm_chain.prompt.template[index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386831ee-3328-4721-8727-f45fb5fae5c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phrase= \"Begin!\"\n",
    "\n",
    "primer= '''\\n\\nFor the questions being asked, ALWAYS use all the tools in a sequence defined in the <sequence> tags without skipping tools to generate an answer\\n\\n<sequence> sql_db_list_tables -> sql_db_schema_and_sample_rows -> sql_db_query </sequence>\\n\\n-ALWAYS generate a SQL Query after examining the database using the `sql_db_schema_and_sample_rows` tool.\\n-Execute the SQL Query using the `sql_db_query` tool.\\n-NEVER generate results without querying the database using the `sql_db_query` tool. Execute all steps using tools, without pausing for input from user.\\n-ALWAYS generate an answer after examining `Observation` from tool's response.\\n\\nPay attention to SQL Queries generated.\\n- Do not use colon `:` in the SQL Query. It causes this error \"Error: (sqlalchemy.exc.InvalidRequestError) A value is required for bind parameter\".\\n- Do not use aliases in generating the SQL Query.\\n- When querying column of `string` type, use single quotes ' in SQL Query for casting to string.\\n- LIMIT query to 10 results.\\n- Don't use table JOIN, unless you absolutely have to.\\n- Do not use backtick ` in the SQL Query.\\n\\nONLY when asked to generate figure/charts/plots for results, generate code to show the figure/charts/plots. Then execute the generated code using the Python_REPL tool to make sure the code successfully generates the figure.\\n\\n\\n'''\n",
    "\n",
    "index= conversational_agent.agent.llm_chain.prompt.template.find(phrase)\n",
    "\n",
    "primer= primer\n",
    "\n",
    "conversational_agent.agent.llm_chain.prompt.template= conversational_agent.agent.llm_chain.prompt.template[:index] + primer + conversational_agent.agent.llm_chain.prompt.template[index:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f4fe8d-2ab1-467e-8411-a8dfd35da2b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(conversational_agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a938670-8b3e-47c0-99b6-b2fbd617d93a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ignore alternative between human and assistant warnings from Claude\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ce3b1a-4f80-41d9-a40d-9e214f89964c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ac44244-a035-40dd-ae50-5de00e81d86d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## A Security Threat Hunter's converation with the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721145ec",
   "metadata": {},
   "source": [
    "Provide the question in the input dialog box and hit enter. To break from the loop you can type exit and hit enter. Use up and down arrows on your keyboard to view previous questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2487ec-5469-4e0d-a72a-356ba4383c35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input(\"\")\n",
    "    if user_input=='exit': break\n",
    "    print(conversational_agent.run(user_input))\n",
    "    print()\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740b9de8-c33c-41c3-ba16-8113bd82af59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a7d94b-2352-40d8-bcc1-a6e2e116fdd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb42c26e-eabc-4b1d-99b2-cf8b8f0765b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Concluding thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1218cb3a-24fd-4f13-8089-90a6d60b0f56",
   "metadata": {},
   "source": [
    "The example use case and run in this Notebook are a product of several prompt instruction trials to combat errors we encountered in using this tool.\n",
    "\n",
    "The agent can sporidically generate fabricated answers without using tools, prompt the agent to use tools. (ex: \"use tools to answer the questions\"). Clearing memory might help further (cell: Adding Conversation Buffer Memory)\n",
    "\n",
    "The PythonREPL tool is currently being utilized to generate code only, and separately run in a cell to show/save plots.\n",
    "\n",
    "Try different models hosted in bedrock!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f982181b-b431-4d7b-b196-7294975258f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4915eb-108e-4c97-bdf8-ff26d983846b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f126b9b-839a-4686-8bd2-aea6b4a4822c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac998f-2901-4b1e-9b50-63f7d1d2fa9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd4f811-ee0d-476e-9487-dd0b1bb578d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
